{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5de887479359>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHDF5Matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import h5py\n",
    "from keras.utils.io_utils import HDF5Matrix\n",
    "from datetime import datetime, timedelta\n",
    "from PIL import Image\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 256\n",
    "kernel_size = 64\n",
    "weight = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_value(array, property):\n",
    "    array = array[property]\n",
    "    array = array.drop_duplicates(keep='last')\n",
    "    array = array.tolist()\n",
    "    array.sort()\n",
    "    return array\n",
    "\n",
    "routes = pd.read_csv('covid19/MergedRoute.csv')\n",
    "dates = unique_value(routes, 'date')\n",
    "patients = unique_value(routes, 'patient_id')\n",
    "dataset_path = 'test_3.h5'\n",
    "model_path = 'model/0518_train_1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['age', 'sex', 'infection_case', 'type', 'date']\n",
    "counts = [11, 2, 4, 21, 7]\n",
    "visit_types = ['karaoke', 'gas_station', 'gym', 'bakery', 'pc_cafe',\n",
    "              'beauty_salon', 'school', 'church', 'bank', 'cafe',\n",
    "              'bar', 'post_office', 'real_estate_agency', 'lodging',\n",
    "              'public_transportation', 'restaurant', 'etc', 'store',\n",
    "              'hospital', 'pharmacy', 'airport']\n",
    "causes = ['community infection', 'etc', 'contact with patient', 'overseas inflow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patient:\n",
    "    def age_category(age):\n",
    "        age = int(age[:-1])\n",
    "        if age == 0: return 0\n",
    "        elif age == 100: return 10\n",
    "        return age // 10\n",
    "            \n",
    "    def sex_category(sex):\n",
    "        if sex == 'male': return 0\n",
    "        return 1\n",
    "\n",
    "    def infection_case_category(infection_case, causes):\n",
    "        return causes.index(infection_case)\n",
    "    \n",
    "    def type_category(visit_type, move_types):\n",
    "        return move_types.index(visit_type)\n",
    "\n",
    "    def day_category(day):\n",
    "        day = datetime.strptime(day, \"%Y-%m-%d\")\n",
    "        return day.weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_places(places, counts, causes, visit_types):\n",
    "    indices = []\n",
    "    for i in range(len(places)):\n",
    "        one_visit = places.iloc[i]\n",
    "        indices.append(df_to_grid_index(one_visit, counts, causes, visit_types))\n",
    "    return indices\n",
    "\n",
    "def df_to_grid_index(one_visit, counts, causes, visit_types):\n",
    "    index = 0\n",
    "    p_age = Patient.age_category(one_visit['age'])\n",
    "    index += counts[0]\n",
    "    p_sex = Patient.sex_category(one_visit['sex']) + index\n",
    "    index += counts[1]\n",
    "    p_infection_case = Patient.infection_case_category(one_visit['infection_case'], causes) + index\n",
    "    index += counts[2]\n",
    "    p_type = Patient.type_category(one_visit['type'], visit_types) + index\n",
    "    index += counts[3]\n",
    "    p_date = Patient.day_category(one_visit['date']) + index\n",
    "    row = one_visit['row']\n",
    "    col = one_visit['col']\n",
    "    \n",
    "    return [p_age, p_sex, p_infection_case, p_type, p_date, row, col]\n",
    "\n",
    "def put_triangular_kernel(array, row, col, value, depth):\n",
    "    stride = int((depth - 1) / 2)\n",
    "    ratio = 1 / (stride + 1)\n",
    "    \n",
    "    c = 1\n",
    "    \n",
    "    for i in range(stride, 0, -1):\n",
    "        if row - i >=0 and row - i < array.shape[0] and col-i>=0 and col-i<array.shape[1]:\n",
    "            array[row - i][col-i] += (c * ratio * value)\n",
    "\n",
    "        if row - i >= 0 and row-i<array.shape[0] and col+i <array.shape[1]:\n",
    "            array[row - i][col+i] += (c * ratio * value)\n",
    "            \n",
    "        if row + i < array.shape[0] and row + i >= 0 and col-i >= 0 :\n",
    "            array[row + i][col-i] += (c * ratio * value)\n",
    "            \n",
    "        if row + i < array.shape[0] and row + i >= 0 and col+i <array.shape[1]:\n",
    "            array[row + i][col+i] += (c * ratio * value)\n",
    "            \n",
    "        for j in range(col-i + 1, col+i):\n",
    "            if row-i >= 0 and j >= 0 and row-i<array.shape[0] and j<array.shape[1]:\n",
    "                array[row-i][j] += (c * ratio * value)\n",
    "            if j >= 0 and j < array.shape[1] and row+i<array.shape[0]:\n",
    "                array[row+i][j] += (c * ratio * value)\n",
    "\n",
    "        for j in range(row+i - 1, row-i, -1):\n",
    "            if col + i >= 0 and col+i<array.shape[1] and j >=0 and j<array.shape[1]:\n",
    "                array[j][col + i] += (c * ratio * value)\n",
    "            if col - i >= 0 and col-i<array.shape[1] and j<array.shape[1] and j>=0:\n",
    "                array[j][col - i] += (c * ratio * value)\n",
    "        c += 1\n",
    "    \n",
    "    array[row][col] = value\n",
    "    \n",
    "    return array\n",
    "\n",
    "def overlay_kernel(array):\n",
    "    new_image = np.zeros((array.shape[0],array.shape[1]))\n",
    "    for row in range(array.shape[0]):\n",
    "        for col in range(array.shape[1]):\n",
    "            if array[row][col] == 0: continue\n",
    "            new_image += put_triangular_kernel(np.zeros((array.shape[0], array.shape[1])), row, col, array[row][col], kernel_size)\n",
    "    image_array = new_image\n",
    "        \n",
    "    return new_image\n",
    "\n",
    "def indices_save_image(path, place_indices):\n",
    "    all_counts = sum(count for count in counts)\n",
    "    visit_grid = np.zeros((all_counts, size, size))\n",
    "    \n",
    "    for index in place_indices:\n",
    "        row = index[5]\n",
    "        col = index[6]\n",
    "        for feature in range(5):\n",
    "            visit_grid[index[feature]][row][col] += weight\n",
    "    \n",
    "    for channel in range(visit_grid.shape[0]):\n",
    "        save_grid(path + str(channel) + \".png\", visit_grid[channel])\n",
    "    \n",
    "def save_grid(path, grid):\n",
    "    grid = overlay_kernel(grid)\n",
    "    img = Image.fromarray(grid.astype('uint8'), 'L')\n",
    "    img.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_patient_route(path, patient, routes):\n",
    "    patient_places = routes[routes['patient_id']==patient]\n",
    "    patient_dates = unique_value(patient_places, 'date')\n",
    "    first_day = datetime.strptime(patient_dates[0], \"%Y-%m-%d\")\n",
    "    last_day = datetime.strptime(patient_dates[-1], \"%Y-%m-%d\") # + timedelta(days=3)\n",
    "    delta = last_day - first_day\n",
    "    duration = delta.days + 1\n",
    "\n",
    "    # 저장\n",
    "    patient_path = path + str(patient)\n",
    "    Path(patient_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    today = first_day\n",
    "    while(True):\n",
    "        today_str = datetime.strftime(today, \"%Y-%m-%d\")\n",
    "        patient_day_places = patient_places[patient_places['date']==today_str]\n",
    "        places_indices = combine_places(patient_day_places, counts, causes, visit_types)\n",
    "        patient_date_path = patient_path + \"/\" + today_str + '/'\n",
    "        Path(patient_date_path).mkdir(parents=True, exist_ok=True)\n",
    "        indices_save_image(patient_date_path, places_indices)\n",
    "        if today == last_day: break\n",
    "        today += timedelta(days=1)\n",
    "\n",
    "def get_patient_route(patient, routes):\n",
    "    patient_places = routes[routes['patient_id']==patient]\n",
    "    patient_dates = unique_value(patient_places, 'date')\n",
    "    first_day = datetime.strptime(patient_dates[0], \"%Y-%m-%d\")\n",
    "    last_day = datetime.strptime(patient_dates[-1], \"%Y-%m-%d\") # + timedelta(days=3)\n",
    "    delta = last_day - first_day\n",
    "    duration = delta.days + 1\n",
    "\n",
    "    patient_routes = []\n",
    "    today = first_day\n",
    "    while(True):\n",
    "        today_str = datetime.strftime(today, \"%Y-%m-%d\")\n",
    "        patient_day_places = patient_places[patient_places['date']==today_str]\n",
    "        places_indices = combine_places(patient_day_places, counts, causes, visit_types)\n",
    "        patient_routes.append([today_str, places_indices]) \n",
    "\n",
    "        if today == last_day: break\n",
    "        today += timedelta(days=1)\n",
    "        \n",
    "    return patient_routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 확진자 기준으로 raw data 저장\n",
    "```\n",
    "path = 'covid_images/patient_figure_raw_64_30_3/'\n",
    "for patient in patients:\n",
    "    save_patient_route(path, patient, routes)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3일 누적 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_two_days(day1, day2):\n",
    "    day2[1].extend(day1[1])\n",
    "    return day2\n",
    "    \n",
    "def accumulate_patient(patient, routes):\n",
    "    patient_route = get_patient_route(patient, routes)\n",
    "    patient_days = len(patient_route)\n",
    "\n",
    "    second = patient_days - 1\n",
    "    first = second - 1\n",
    "    for i in range(2 * patient_days - 3):\n",
    "        patient_route[second] = accumulate_two_days(patient_route[first], patient_route[second])\n",
    "        if second - first == 2: second -=1\n",
    "        else: first -= 1\n",
    "    \n",
    "    return patient_route\n",
    "\n",
    "def save_patient_routes(path, patient, patient_routes):\n",
    "    path += str(patient) + '/'\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    for routes in patient_routes:\n",
    "        patient_date_path = path + routes[0] + '/'\n",
    "        Path(patient_date_path).mkdir(parents=True, exist_ok=True)\n",
    "        indices_save_image(patient_date_path, routes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 누적 경로 저장\n",
    "```\n",
    "path = 'covid_images/patient_figure_accumulated_64_30_3/'\n",
    "for patient in patients:\n",
    "    accumulated_routes = accumulate_patient(patient, routes)\n",
    "    save_patient_routes(path, patient, accumulated_routes)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 날짜별 취합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complete_routes(routes, dates, patients):\n",
    "    first_day = datetime.strptime(dates[0], \"%Y-%m-%d\")\n",
    "    last_day = datetime.strptime(dates[-1], \"%Y-%m-%d\") # + timedelta(days=3)\n",
    "\n",
    "    # 날짜별 경로 배열 생성\n",
    "    today = first_day\n",
    "    complete_routes = []\n",
    "    while(True):\n",
    "        today_str = datetime.strftime(today, \"%Y-%m-%d\")\n",
    "        places = []\n",
    "        complete_routes.append([today_str, places])\n",
    "\n",
    "        if today == last_day: break\n",
    "        today += timedelta(days=1)\n",
    "\n",
    "    # 환자 경로 가져온 다음 날짜대로 배치\n",
    "    for patient in patients:\n",
    "        accumulated_routes = accumulate_patient(patient, routes)\n",
    "        for each_route in accumulated_routes:\n",
    "            route_day = datetime.strptime(each_route[0], \"%Y-%m-%d\")\n",
    "            route_places = each_route[1]\n",
    "            index = (route_day - first_day).days\n",
    "            complete_routes[index][1].extend(route_places)\n",
    "    return complete_routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 취합한 경로 저장\n",
    "```\n",
    "complete_routes = get_complete_routes(routes, dates, patients)\n",
    "\n",
    "path = 'covid_images/complete_figure_kernel_64_10_5/'\n",
    "Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for days in complete_routes:\n",
    "    date_path = path + days[0] + '/'\n",
    "    Path(date_path).mkdir(parents=True, exist_ok=True)\n",
    "    indices_save_image(date_path, days[1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아직 하는 중\n",
    "```\n",
    "def get_accumulated_routes_by_date(routes, dates, patients):\n",
    "    first_day = datetime.strptime(dates[0], \"%Y-%m-%d\")\n",
    "    last_day = datetime.strptime(dates[-1], \"%Y-%m-%d\")\n",
    "\n",
    "    # 날짜별 경로 배열 생성\n",
    "    today = first_day\n",
    "    complete_routes = []\n",
    "    while(True):\n",
    "        today_str = datetime.strftime(today, \"%Y-%m-%d\")\n",
    "        ids = []\n",
    "        places = []\n",
    "        complete_routes.append([today_str, []])\n",
    "        if today == last_day: break\n",
    "        today += timedelta(days=1)\n",
    "\n",
    "    for patient in patients:\n",
    "        accumulated_routes = accumulate_patient(patient, routes)\n",
    "        for each_route in accumulated_routes:\n",
    "            route_day = datetime.strptime(each_route[0], \"%Y-%m-%d\")\n",
    "            route_places = each_route[1]\n",
    "            index = (route_day - first_day).days\n",
    "            complete_routes[index][1].append([patient, route_places])\n",
    "    return complete_routes\n",
    "\n",
    "accumulated_routes = get_accumulated_routes_by_date(routes, dates, patients)\n",
    "\n",
    "path = 'covid_images/patient_accumulated_by_date/'\n",
    "Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for days in accumulated_routes:\n",
    "    date_path = path + days[0] + '/'\n",
    "    Path(date_path).mkdir(parents=True, exist_ok=True)\n",
    "    for day in days[1]:\n",
    "        patient_id = day[0]\n",
    "        routes = day[1]\n",
    "        day_path = date_path + str(patient_id) + '/'\n",
    "        Path(day_path).mkdir(parents=True, exist_ok=True)\n",
    "        indices_save_image(day_path, routes)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(routes, dates, patients):\n",
    "    complete_routes = get_complete_routes(routes, dates, patients)\n",
    "    all_counts = sum(count for count in counts)\n",
    "    dataset = np.zeros((len(complete_routes), all_counts, size, size))\n",
    "\n",
    "    for i, days in enumerate(complete_routes):\n",
    "        sub_routes = get_array_image(days, dataset[i,:,:,:])\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def get_array_image(place_indices, data_array):\n",
    "    all_counts = sum(count for count in counts)\n",
    "    \n",
    "    for index in place_indices[1]:\n",
    "        row = index[5]\n",
    "        col = index[6]\n",
    "        for feature in range(5):\n",
    "            data_array[index[feature]][row][col] += weight\n",
    "    \n",
    "    for channel in range(data_array.shape[0]):\n",
    "        data_array[channel] = overlay_kernel(data_array[channel])\n",
    "    \n",
    "    return data_array\n",
    "    \n",
    "def split_dataset(dataset, n_train, n_step):\n",
    "    n = dataset.shape[0]\n",
    "    channel = dataset.shape[1]\n",
    "\n",
    "    n_train = int(n * 0.7) if n_train == 0 else n_train\n",
    "    n_test = n - n_train\n",
    "\n",
    "    train = dataset[:n_train,:,:]\n",
    "    test = dataset[n_train:,:,:]\n",
    "\n",
    "    # train set\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(n_step, n_train-n_step + 1):\n",
    "        X_train.append(train[i-n_step:i, :,:])\n",
    "        y_train.append(train[i:i+n_step, :,:])\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "   \n",
    "    \n",
    "    # test set\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(n_step,n_test):\n",
    "        X_test.append(train[i-n_step:i, :,:])\n",
    "        y_test.append(train[i:i+1, :,:])\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "   \n",
    "    return X_train, y_train, X_test, y_test\n",
    "    \n",
    "def save_dataset(path, X_train, y_train, X_test, y_test):\n",
    "    with h5py.File(path,'w') as f:    \n",
    "        train_X = f.create_dataset('X_train', data=X_train)\n",
    "        train_y = f.create_dataset('y_train', data=y_train)\n",
    "        test_X = f.create_dataset('X_test', data=X_test)\n",
    "        test_y = f.create_dataset('y_test', data=y_test)\n",
    "    \n",
    "def load_data(path):\n",
    "    X_train = HDF5Matrix(path, 'X_train')\n",
    "    y_train = HDF5Matrix(path, 'y_train')\n",
    "    X_test = HDF5Matrix(path, 'X_test')\n",
    "    y_test = HDF5Matrix(path, 'y_test')\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save dataset\n",
    "```\n",
    "dataset = get_dataset(routes, dates, patients)\n",
    "X_train, y_train, X_test, y_test = split_dataset(dataset, 60, 3)\n",
    "save_dataset(dataset_path , X_train, y_train, X_test, y_test)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as tfback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 256\n",
    "channel = 45\n",
    "n_step = 3\n",
    "n_test = 3\n",
    "epochs = 50\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a layer which take as input movies of shape\n",
    "# (n_frames, width, height, channels) and returns a movie\n",
    "# of identical shape.\n",
    "def get_model(channel):\n",
    "    with K.tf_ops.device('/GPU:0'):\n",
    "        seq = Sequential()\n",
    "        seq.add(ConvLSTM2D(filters=channel, kernel_size=(3, 3), data_format='channels_first',\n",
    "                           input_shape=(n_step, channel, rs, rs),\n",
    "                           padding='same', return_sequences=True))\n",
    "        seq.add(BatchNormalization())\n",
    "\n",
    "        seq.add(ConvLSTM2D(filters=channel, kernel_size=(3, 3), data_format='channels_first',\n",
    "                           padding='same', return_sequences=True))\n",
    "        seq.add(BatchNormalization())\n",
    "\n",
    "        seq.add(ConvLSTM2D(filters=channel, kernel_size=(3, 3), data_format='channels_first',\n",
    "                           padding='same', return_sequences=True))\n",
    "        seq.add(BatchNormalization())\n",
    "\n",
    "        seq.add(ConvLSTM2D(filters=channel, kernel_size=(3, 3), data_format='channels_first',\n",
    "                           padding='same', return_sequences=True))\n",
    "        seq.add(BatchNormalization())\n",
    "\n",
    "        seq.add(Conv3D(filters=n_step, kernel_size=(3, 3, 3),\n",
    "                       activation='sigmoid',\n",
    "                       padding='same', data_format='channels_first'))\n",
    "\n",
    "#         seq.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "        seq.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "                \n",
    "        seq.summary()\n",
    "\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array_image(place_indices, data_array):\n",
    "    all_counts = sum(count for count in counts)\n",
    "    \n",
    "    for index in place_indices[1]:\n",
    "        row = index[5]\n",
    "        col = index[6]\n",
    "        for feature in range(5):\n",
    "            data_array[index[feature]][row][col] += weight\n",
    "    \n",
    "    for channel in range(data_array.shape[0]):\n",
    "        data_array[channel] = overlay_kernel(data_array[channel])\n",
    "    \n",
    "    return data_array\n",
    "\n",
    "def train(X_train, y_train):\n",
    "    seq = get_model(channel)\n",
    "    seq.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, shuffle='batch')\n",
    "    seq.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 데이터셋 불러오기\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 트레이닝 함수 실행\n",
    "\n",
    "train(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### predict 함수 실행\n",
    "\n",
    "model = load_model(model_path)\n",
    "pred =model.predict(X_test)\n",
    "print(pred.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
